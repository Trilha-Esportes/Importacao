{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "source": [
    "1. Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import (\n",
    "    create_engine, Table, Column, Integer, String, Float, Numeric, Date,\n",
    "    CheckConstraint, ForeignKey, func, MetaData\n",
    ")\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy.sql import text\n",
    "from datetime import datetime\n",
    "import os\n",
    "import logging\n",
    "\n",
    "import argparse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opcional -> CONFIGURAÇÕES DE LOGGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração básica do logging\n",
    "# logging.basicConfig(\n",
    "#     level=logging.INFO,\n",
    "#     format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "#     handlers=[\n",
    "#         logging.FileHandler(\"processamento.log\"),\n",
    "#         logging.StreamHandler()\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. CONFIGURAÇÕES DE BANCO DE DADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurações da conexão com o PostgreSQL na GCP usando variáveis de ambiente\n",
    "DATABASE_CONFIG = {\n",
    "    'username': os.getenv('DB_USERNAME', 'postgres'),\n",
    "    'password': os.getenv('DB_PASSWORD', 'U7urkInVDg[(D^{&'),  # Ajuste conforme necessário\n",
    "    'host': os.getenv('DB_HOST', '34.130.95.218'),\n",
    "    'port': os.getenv('DB_PORT', '5432'),\n",
    "    'database': os.getenv('DB_NAME', 'postgres'),\n",
    "}\n",
    "\n",
    "def get_database_url(config):\n",
    "    \"\"\"\n",
    "    Constrói a URL de conexão para o PostgreSQL.\n",
    "    \"\"\"\n",
    "    return f\"postgresql://{config['username']}:{config['password']}@{config['host']}:{config['port']}/{config['database']}\"\n",
    "\n",
    "# Criação do engine de conexão\n",
    "DATABASE_URL = get_database_url(DATABASE_CONFIG)\n",
    "engine = create_engine(DATABASE_URL, echo=False)  # echo=False para reduzir a verbosidade dos logs\n",
    "metadata = MetaData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. DEFINIÇÃO DAS TABELAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição da tabela marketplaces\n",
    "marketplaces = Table(\n",
    "    'marketplaces', metadata,\n",
    "    Column('id', Integer, primary_key=True, autoincrement=True),\n",
    "    Column('nome', String(255), nullable=False),\n",
    "    Column('descricao', String, nullable=True),\n",
    "    extend_existing=True  # Permite redefinir a tabela se já existir no MetaData\n",
    ")\n",
    "\n",
    "# Definição da tabela arquivos_processados\n",
    "arquivos_processados = Table(\n",
    "    'arquivos_processados', metadata,\n",
    "    Column('id', Integer, primary_key=True, autoincrement=True),\n",
    "    Column('nome_arquivo', String(255), nullable=False, unique=True),\n",
    "    Column('data_processo', Date, nullable=False, server_default=func.current_date()),\n",
    "    Column('status', String(50), nullable=False),\n",
    "    Column('observacoes', String, nullable=True),\n",
    "    CheckConstraint(\"status IN ('PENDENTE', 'PROCESSADO', 'ERRO')\", name='status_check'),\n",
    "    extend_existing=True\n",
    ")\n",
    "\n",
    "# Definição da tabela sku_marketplace\n",
    "sku_marketplace = Table(\n",
    "    'sku_marketplace', metadata,\n",
    "    Column('id', Integer, primary_key=True, autoincrement=True),\n",
    "    Column('marketplace_id', Integer, ForeignKey('marketplaces.id'), nullable=False),\n",
    "    Column('numero_pedido', String(50), nullable=False),\n",
    "    Column('valor_liquido', Float, nullable=False),\n",
    "    Column('valor_bruto', Float, nullable=True),\n",
    "    Column('valor_final', Float, nullable=False),\n",
    "    Column('valor_frete', Float, nullable=True),\n",
    "    extend_existing=True\n",
    ")\n",
    "\n",
    "# Definição da tabela comissoes_pedido\n",
    "comissoes_pedido = Table(\n",
    "    'comissoes_pedido', metadata,\n",
    "    Column('id', Integer, primary_key=True, autoincrement=True),\n",
    "    Column('data', Date, nullable=False),\n",
    "    Column('porcentagem', Numeric(5,4), nullable=False),\n",
    "    Column('sku_marketplace_id', Integer, ForeignKey('sku_marketplace.id'), nullable=False),\n",
    "    CheckConstraint(\"porcentagem >= 0 AND porcentagem <= 1\", name='comissoes_pedido_porcentagem_check'),\n",
    "    extend_existing=True\n",
    ")\n",
    "\n",
    "# Definição da tabela comissoes_periodo\n",
    "comissoes_periodo = Table(\n",
    "    'comissoes_periodo', metadata,\n",
    "    Column('id', Integer, primary_key=True, autoincrement=True),\n",
    "    Column('data_inicio', Date, nullable=False),\n",
    "    Column('data_fim', Date, nullable=False),\n",
    "    Column('porcentagem', Numeric(5,4), nullable=False),\n",
    "    Column('sku_marketplace', String(255), nullable=True),\n",
    "    Column('marketplace_id', Integer, ForeignKey('marketplaces.id'), nullable=True),\n",
    "    extend_existing=True\n",
    ")\n",
    "\n",
    "evento_centauro = Table(\n",
    "    'evento_centauro', metadata,\n",
    "    Column('id', Integer, primary_key=True, autoincrement=True),\n",
    "    Column('numero_pedido', String(50), nullable=False),\n",
    "    Column('tipo_evento', String(255), nullable=True),\n",
    "    Column('repasse_liquido_evento', Float, nullable=False),\n",
    "    Column('data', Date, nullable=False),\n",
    "    extend_existing=True\n",
    ")\n",
    "# Criação das tabelas no banco (se não existirem)\n",
    "metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. CONFIGURAÇÃO DO SQLALCHEMY ORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. FUNÇÕES AUXILIARES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def verificar_marketplace_id(marketplace_id=5):\n",
    "    \"\"\"\n",
    "    Verifica se o marketplace_id existe na tabela marketplaces.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        query = marketplaces.select().where(marketplaces.c.id == marketplace_id)\n",
    "        result = session.execute(query).fetchone()\n",
    "        if result:\n",
    "            logger.info(f\"Marketplace com ID {marketplace_id} encontrado.\")\n",
    "            return True\n",
    "        else:\n",
    "            logger.error(f\"Marketplace com ID {marketplace_id} não encontrado.\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao verificar marketplace_id {marketplace_id}: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def parse_date_from_filename(filename):\n",
    "    base = os.path.basename(filename)\n",
    "    try:\n",
    "        date_part = base.split(' - ')[0]  # Exemplo: \"2024-09\"\n",
    "        year, month = map(int, date_part.split('-'))\n",
    "        return datetime(year, month, 1).date()\n",
    "    except ValueError as ve:\n",
    "        logger.error(f\"Erro ao extrair data do nome '{filename}': {ve}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro inesperado ao extrair data do nome '{filename}': {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def inserir_arquivos_processados(nome_arquivo, data_processo, status, observacoes=None):\n",
    "    \"\"\"\n",
    "    Insere ou verifica o processamento de arquivos na tabela 'arquivos_processados'.\n",
    "    \n",
    "    Parâmetros:\n",
    "    - nome_arquivo (str): Nome do arquivo CSV.\n",
    "    - data_processo (date): Data de processamento.\n",
    "    - status (str): Status do processamento ('PENDENTE', 'PROCESSADO', 'ERRO', 'REPROCESSANDO').\n",
    "    - observacoes (str, optional): Observações adicionais.\n",
    "    \n",
    "    Retorna:\n",
    "    - bool: True se o arquivo foi inserido com sucesso, False se já estava processado ou houve erro.\n",
    "    \"\"\"\n",
    "    if isinstance(data_processo, datetime):\n",
    "        data_processo = data_processo.date()\n",
    "    if data_processo is None:\n",
    "        data_processo = datetime.now().date()\n",
    "\n",
    "    try:\n",
    "        with engine.begin() as conn:\n",
    "            # Verifica se o arquivo já foi processado\n",
    "            sel = text(\"\"\"\n",
    "                SELECT id, status\n",
    "                FROM arquivos_processados\n",
    "                WHERE nome_arquivo = :na\n",
    "            \"\"\")\n",
    "            row = conn.execute(sel, {\"na\": nome_arquivo}).fetchone()\n",
    "\n",
    "            if row:\n",
    "                # Acessa o status usando o índice correto (1)\n",
    "                logger.warning(f\"[arquivos_processados] Arquivo '{nome_arquivo}' já foi processado com status '{row[1]}'.\")\n",
    "                return False  # Indica que o arquivo já foi processado\n",
    "\n",
    "            # Insere o arquivo como processado\n",
    "            sql = text(\"\"\"\n",
    "                INSERT INTO arquivos_processados (nome_arquivo, data_processo, status, observacoes)\n",
    "                VALUES (:na, :dp, :st, :obs)\n",
    "            \"\"\")\n",
    "            conn.execute(\n",
    "                sql, {\"na\": nome_arquivo, \"dp\": data_processo, \"st\": status, \"obs\": observacoes})\n",
    "        logger.info(f\"[arquivos_processados] Inserido => '{nome_arquivo}' / {status}\")\n",
    "        return True  # Indica que o arquivo foi inserido com sucesso\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao inserir em 'arquivos_processados': {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def inserir_comissoes_pedido(data_pedido, porcentagem_comissao, sku_marketplace_id):\n",
    "    \"\"\"\n",
    "    Insere uma comissão na tabela 'comissoes_pedido'.\n",
    "    \n",
    "    Parâmetros:\n",
    "    - data_pedido (date): A data do pedido.\n",
    "    - porcentagem_comissao (float): A porcentagem da comissão (0-1).\n",
    "    - sku_marketplace_id (int): ID do SKU no marketplace.\n",
    "    \"\"\"\n",
    "    pc = round(porcentagem_comissao, 4)\n",
    "    if not (0 <= pc <= 1):\n",
    "        raise ValueError(\"Porcentagem de comissão fora do intervalo (0-1).\")\n",
    "\n",
    "    try:\n",
    "        with engine.begin() as conn:\n",
    "            sql = text(\"\"\"\n",
    "                INSERT INTO comissoes_pedido (data, porcentagem, sku_marketplace_id)\n",
    "                VALUES (:dt, :pc, :sid)\n",
    "            \"\"\")\n",
    "            conn.execute(sql, {\"dt\": data_pedido, \"pc\": pc,\n",
    "                             \"sid\": sku_marketplace_id})\n",
    "        logger.info(f\"[comissoes_pedido] Inserido => sku_marketplace_id={sku_marketplace_id}, pc={pc*100:.2f}%.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro inserir_comissoes_pedido: {e}\")\n",
    "\n",
    "\n",
    "def upsert_sku_marketplace(pedido, marketplace_id=5):\n",
    "    \"\"\"\n",
    "    Garante que o pedido exista na tabela sku_marketplace.\n",
    "    Se não existir, insere com valores padrão (0 ou NULL).\n",
    "    Retorna o ID do sku_marketplace.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with engine.begin() as conn:\n",
    "            sel = text(\"\"\"\n",
    "                SELECT id\n",
    "                FROM sku_marketplace\n",
    "                WHERE numero_pedido = :ped\n",
    "            \"\"\")\n",
    "            row = conn.execute(sel, {\"ped\": pedido}).fetchone()\n",
    "\n",
    "            if row:\n",
    "                sku_id = row[0]\n",
    "                logger.info(f\"[sku_marketplace] Pedido existente => pedido={pedido}, ID={sku_id}\")\n",
    "                return sku_id\n",
    "            else:\n",
    "                ins = text(\"\"\"\n",
    "                    INSERT INTO sku_marketplace\n",
    "                    (marketplace_id, numero_pedido, valor_liquido, valor_frete, valor_final)\n",
    "                    VALUES (:mk, :ped, 0, 0, 0)\n",
    "                    RETURNING id\n",
    "                \"\"\")\n",
    "                ret = conn.execute(ins, {\n",
    "                    \"mk\": marketplace_id,\n",
    "                    \"ped\": pedido\n",
    "                })\n",
    "                sku_id = ret.fetchone()[0]\n",
    "                logger.info(f\"[sku_marketplace] INSERT => pedido={pedido}, ID={sku_id}\")\n",
    "                return sku_id\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro upsert_sku_marketplace: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def atualizar_sku_marketplace_repasse(pedido, valor_pedido, valor_frete, valor_final, marketplace_id=5):\n",
    "    \"\"\"\n",
    "    Atualiza os valores de repasse normal na tabela sku_marketplace.\n",
    "    Se o pedido não existir, insere com os valores fornecidos.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with engine.begin() as conn:\n",
    "            sel = text(\"\"\"\n",
    "                SELECT id\n",
    "                FROM sku_marketplace\n",
    "                WHERE numero_pedido = :ped\n",
    "            \"\"\")\n",
    "            row = conn.execute(sel, {\"ped\": pedido}).fetchone()\n",
    "\n",
    "            if row:\n",
    "                sku_id = row[0]\n",
    "                upd = text(\"\"\"\n",
    "                    UPDATE sku_marketplace\n",
    "                    SET\n",
    "                        valor_liquido = :vliq,\n",
    "                        valor_frete   = :vfre,\n",
    "                        valor_final   = :vfin\n",
    "                    WHERE id = :sid\n",
    "                \"\"\")\n",
    "                conn.execute(upd, {\n",
    "                    \"vliq\": valor_pedido,\n",
    "                    \"vfre\": valor_frete,\n",
    "                    \"vfin\": valor_final,\n",
    "                    \"sid\":  sku_id\n",
    "                })\n",
    "                logger.info(f\"[sku_marketplace] UPDATE => pedido={pedido}, ID={sku_id}\")\n",
    "                return sku_id\n",
    "            else:\n",
    "                ins = text(\"\"\"\n",
    "                    INSERT INTO sku_marketplace\n",
    "                    (marketplace_id, numero_pedido, valor_liquido, valor_frete, valor_final)\n",
    "                    VALUES (:mk, :ped, :vliq, :vfre, :vfin)\n",
    "                    RETURNING id\n",
    "                \"\"\")\n",
    "                ret = conn.execute(ins, {\n",
    "                    \"mk\": marketplace_id,\n",
    "                    \"ped\": pedido,\n",
    "                    \"vliq\": valor_pedido,\n",
    "                    \"vfre\": valor_frete,\n",
    "                    \"vfin\": valor_final\n",
    "                })\n",
    "                sku_id = ret.fetchone()[0]\n",
    "                logger.info(f\"[sku_marketplace] INSERT => pedido={pedido}, ID={sku_id}\")\n",
    "                return sku_id\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro atualizar_sku_marketplace_repasse: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def upsert_evento_centauro(numero_pedido, tipo_evento, repasse_liquido, data, data_repasse=None):\n",
    "    \"\"\"\n",
    "    Upsert em evento_centauro. \n",
    "    - Se (numero_pedido, tipo_evento) já existir, atualiza repasse_liquido_evento, data, data_repasse.\n",
    "    - Se o tipo_evento for diferente de 'Repasse Normal' e já existir um pedido com o mesmo numero_pedido,\n",
    "      soma repasse_liquido_evento ao existente.\n",
    "    - Senão, insere um novo registro.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with engine.begin() as conn:\n",
    "            # Verifica se já existe um evento com o mesmo numero_pedido e tipo_evento\n",
    "            sel = text(\"\"\"\n",
    "                SELECT id, repasse_liquido_evento\n",
    "                FROM evento_centauro\n",
    "                WHERE numero_pedido = :ped\n",
    "                  AND tipo_evento = :tevt\n",
    "            \"\"\")\n",
    "            row = conn.execute(sel, {\n",
    "                \"ped\": numero_pedido,\n",
    "                \"tevt\": tipo_evento\n",
    "            }).fetchone()\n",
    "\n",
    "            if row:\n",
    "                ec_id, repasse_existente = row\n",
    "                if tipo_evento not in [\"Repasse Normal\", \"Repasse - Normal\"]:\n",
    "                    # Converte repasse_existente para float antes de somar\n",
    "                    novo_repasse = float(repasse_existente) + repasse_liquido\n",
    "                    upd = text(\"\"\"\n",
    "                        UPDATE evento_centauro\n",
    "                        SET repasse_liquido_evento = :rle,\n",
    "                            data = :dt,\n",
    "                            data_repasse = :dr\n",
    "                        WHERE id = :id\n",
    "                    \"\"\")\n",
    "                    conn.execute(upd, {\n",
    "                        \"rle\": novo_repasse,\n",
    "                        \"dt\":  data,\n",
    "                        \"dr\":  data_repasse,\n",
    "                        \"id\":  ec_id\n",
    "                    })\n",
    "                    logger.info(f\"[evento_centauro] UPDATE (soma repasse) => pedido={numero_pedido}, tipo={tipo_evento}, ID={ec_id}, novo_repasse={novo_repasse}\")\n",
    "                else:\n",
    "                    # Atualiza normalmente para 'Repasse Normal'\n",
    "                    upd = text(\"\"\"\n",
    "                        UPDATE evento_centauro\n",
    "                        SET repasse_liquido_evento = :rle,\n",
    "                            data = :dt,\n",
    "                            data_repasse = :dr\n",
    "                        WHERE id = :id\n",
    "                    \"\"\")\n",
    "                    conn.execute(upd, {\n",
    "                        \"rle\": repasse_liquido,\n",
    "                        \"dt\":  data,\n",
    "                        \"dr\":  data_repasse,\n",
    "                        \"id\":  ec_id\n",
    "                    })\n",
    "                    logger.info(f\"[evento_centauro] UPDATE => pedido={numero_pedido}, tipo={tipo_evento}, ID={ec_id}\")\n",
    "                return ec_id\n",
    "            else:\n",
    "                # Se não existir, insere um novo registro\n",
    "                ins = text(\"\"\"\n",
    "                    INSERT INTO evento_centauro\n",
    "                    (numero_pedido, tipo_evento, repasse_liquido_evento, data, data_repasse)\n",
    "                    VALUES (:ped, :tevt, :rle, :dt, :dr)\n",
    "                    RETURNING id\n",
    "                \"\"\")\n",
    "                ret = conn.execute(ins, {\n",
    "                    \"ped\": numero_pedido,\n",
    "                    \"tevt\": tipo_evento,\n",
    "                    \"rle\": repasse_liquido,\n",
    "                    \"dt\":  data,\n",
    "                    \"dr\":  data_repasse\n",
    "                })\n",
    "                ec_id = ret.fetchone()[0]\n",
    "                logger.info(f\"[evento_centauro] INSERT => pedido={numero_pedido}, tipo={tipo_evento}, ID={ec_id}\")\n",
    "                return ec_id\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro upsert_evento_centauro: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def processar_csv(file_path, reprocessar=True):\n",
    "    \"\"\"\n",
    "    Lê o CSV, interpretando 'Pedido' como string (ex. '00000000002').\n",
    "    - Insere todos os pedidos na tabela sku_marketplace.\n",
    "    - Se status for 'Repasse Normal' ou 'Repasse - Normal':\n",
    "      -> atualiza os valores do repasse normal.\n",
    "    - Se for outro status, apenas registra o evento.\n",
    "    - SEMPRE faz upsert_evento_centauro, registrando o evento e data.\n",
    "    - Se for repasse normal, busca comissão e insere comissoes_pedido.\n",
    "    \"\"\"\n",
    "    nome_arquivo = os.path.basename(file_path)\n",
    "    data_processo = parse_date_from_filename(nome_arquivo)\n",
    "\n",
    "    if not data_processo:\n",
    "        # Atualiza o status para 'ERRO' e adiciona observações\n",
    "        try:\n",
    "            with engine.begin() as conn:\n",
    "                upd = text(\"\"\"\n",
    "                    UPDATE arquivos_processados\n",
    "                    SET status = 'ERRO', observacoes = 'Erro ao extrair data do nome do arquivo.'\n",
    "                    WHERE nome_arquivo = :na\n",
    "                \"\"\")\n",
    "                conn.execute(upd, {\"na\": nome_arquivo})\n",
    "            logger.info(f\"[arquivos_processados] Atualizado => '{nome_arquivo}' / ERRO\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Erro ao atualizar status para 'ERRO' em '{nome_arquivo}': {e}\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, sep=';')\n",
    "\n",
    "        # Tratar '-' como '0'\n",
    "        for col in [\"ValorPedido\", \"ValorFrete\", \"Comissao\", \"RepasseLiquido\"]:\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].replace('-', '0')\n",
    "\n",
    "        logger.info(f\"Lendo CSV '{nome_arquivo}'. Registros: {len(df)}\")\n",
    "\n",
    "        for idx, row in df.iterrows():\n",
    "            pedido_str = str(row.get(\"Pedido\", \"\")).strip()\n",
    "            data_pedido = None\n",
    "            if \"DataPedido\" in row:\n",
    "                dtp = pd.to_datetime(row[\"DataPedido\"], errors='coerce')\n",
    "                if pd.notnull(dtp):\n",
    "                    data_pedido = dtp.date()\n",
    "            data_repasse = None\n",
    "            if \"Ciclo\" in row:\n",
    "                drp = pd.to_datetime(row[\"Ciclo\"], errors='coerce')\n",
    "                if pd.notnull(drp):\n",
    "                    data_repasse = drp.date()\n",
    "\n",
    "            status_venda = str(row.get(\"StatusAtendimento\", \"\")).strip()\n",
    "            valor_pedido = float(row.get(\"ValorPedido\", 0.0))\n",
    "            valor_frete = float(row.get(\"ValorFrete\", 0.0))\n",
    "            valor_final = float(row.get(\"RepasseLiquido\", 0.0))\n",
    "\n",
    "            # 1) Garantir que o pedido exista na tabela sku_marketplace\n",
    "            sku_id = upsert_sku_marketplace(pedido=pedido_str, marketplace_id=5)\n",
    "\n",
    "            # 2) Se status for 'Repasse Normal' ou 'Repasse - Normal', atualiza os valores do repasse\n",
    "            if status_venda in [\"Repasse Normal\", \"Repasse - Normal\"]:\n",
    "                if sku_id:\n",
    "                    # Antes de atualizar, verificar se os valores já correspondem para evitar duplicação\n",
    "                    try:\n",
    "                        with engine.begin() as conn:\n",
    "                            sel = text(\"\"\"\n",
    "                                SELECT valor_liquido, valor_frete, valor_final\n",
    "                                FROM sku_marketplace\n",
    "                                WHERE id = :sid\n",
    "                            \"\"\")\n",
    "                            row_sku = conn.execute(sel, {\"sid\": sku_id}).fetchone()\n",
    "                            if row_sku:\n",
    "                                current_vliq, current_vfre, current_vfin = row_sku\n",
    "                                if (current_vliq != valor_pedido or\n",
    "                                    current_vfre != valor_frete or\n",
    "                                    current_vfin != valor_final):\n",
    "                                    atualizar_sku_marketplace_repasse(\n",
    "                                        pedido=pedido_str,\n",
    "                                        valor_pedido=valor_pedido,\n",
    "                                        valor_frete=valor_frete,\n",
    "                                        valor_final=valor_final,\n",
    "                                        marketplace_id=5\n",
    "                                    )\n",
    "                                else:\n",
    "                                    logger.info(f\"[sku_marketplace] Valores já atualizados para pedido={pedido_str}, ID={sku_id}\")\n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"Erro ao verificar valores para pedido={pedido_str}: {e}\")\n",
    "\n",
    "            # 3) upsert_evento_centauro (sempre)\n",
    "            upsert_evento_centauro(\n",
    "                numero_pedido=pedido_str,\n",
    "                tipo_evento=status_venda,\n",
    "                repasse_liquido=valor_final,\n",
    "                data=data_pedido,\n",
    "                data_repasse=data_repasse\n",
    "            )\n",
    "\n",
    "            # 4) Se status repasse normal, busca comissão e insere se não existir\n",
    "            if status_venda in [\"Repasse Normal\", \"Repasse - Normal\"] and data_pedido and sku_id:\n",
    "                comissao_encontrada = buscar_comissao_periodo(\n",
    "                    data_pedido, pedido_str)\n",
    "                if comissao_encontrada is not None:\n",
    "                    try:\n",
    "                        with engine.begin() as conn:\n",
    "                            sel = text(\"\"\"\n",
    "                                SELECT COUNT(*)\n",
    "                                FROM comissoes_pedido\n",
    "                                WHERE data = :dt\n",
    "                                  AND porcentagem = :pc\n",
    "                                  AND sku_marketplace_id = :sid\n",
    "                            \"\"\")\n",
    "                            count = conn.execute(sel, {\n",
    "                                \"dt\": data_pedido,\n",
    "                                \"pc\": comissao_encontrada,\n",
    "                                \"sid\": sku_id\n",
    "                            }).scalar()\n",
    "                            if count == 0:\n",
    "                                inserir_comissoes_pedido(\n",
    "                                    data_pedido, comissao_encontrada, sku_id)\n",
    "                            else:\n",
    "                                logger.info(f\"[comissoes_pedido] Comissão já inserida para pedido={pedido_str}, ID={sku_id}\")\n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"Erro ao verificar comissão para pedido={pedido_str}: {e}\")\n",
    "                else:\n",
    "                    logger.info(\n",
    "                        f\"Sem comissão p/ '{pedido_str}' data={data_pedido}.\")\n",
    "\n",
    "        # Ao final, marcar o arquivo como processado ou reprocessado\n",
    "        try:\n",
    "            with engine.begin() as conn:\n",
    "                status_final = 'PROCESSADO'\n",
    "                observacoes_final = None\n",
    "                if reprocessar:\n",
    "                    observacoes_final = 'Reprocessamento concluído.'\n",
    "                upd = text(\"\"\"\n",
    "                    UPDATE arquivos_processados\n",
    "                    SET status = :st, observacoes = :obs\n",
    "                    WHERE nome_arquivo = :na\n",
    "                \"\"\")\n",
    "                conn.execute(upd, {\"st\": status_final, \"obs\": observacoes_final, \"na\": nome_arquivo})\n",
    "            logger.info(f\"Processamento do arquivo '{nome_arquivo}' concluído com sucesso.\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Erro ao marcar arquivo '{nome_arquivo}' como PROCESSADO: {e}\")\n",
    "    except:\n",
    "        print(\"ERROU AQQ\")\n",
    "\n",
    "def buscar_comissao_periodo(data_pedido, sku):\n",
    "    \"\"\"\n",
    "    Busca a comissão correspondente ao período e SKU no banco de dados.\n",
    "    \n",
    "    Parâmetros:\n",
    "    - data_pedido (date): A data do pedido.\n",
    "    - sku (str): O SKU do marketplace (numero_pedido).\n",
    "    \n",
    "    Retorna:\n",
    "    - float: A porcentagem da comissão se encontrada, caso contrário, None.\n",
    "    \"\"\"\n",
    "    sql_union = text(\"\"\"\n",
    "        SELECT porcentagem\n",
    "        FROM comissoes_periodo cp\n",
    "        WHERE :data_pedido BETWEEN cp.data_inicio AND cp.data_fim\n",
    "          AND cp.sku_marketplace = :sku\n",
    "          \n",
    "        UNION\n",
    "        \n",
    "        SELECT porcentagem\n",
    "        FROM comissoes_periodo cp\n",
    "        WHERE :data_pedido BETWEEN cp.data_inicio AND cp.data_fim\n",
    "          AND cp.sku_marketplace IS NULL\n",
    "          AND NOT EXISTS (\n",
    "              SELECT 1\n",
    "              FROM comissoes_periodo cp2\n",
    "              WHERE :data_pedido BETWEEN cp2.data_inicio AND cp2.data_fim\n",
    "                AND cp2.sku_marketplace = :sku\n",
    "          )\n",
    "    \"\"\")\n",
    "    try:\n",
    "        with engine.begin() as conn:\n",
    "            row = conn.execute(\n",
    "                sql_union, {\"data_pedido\": data_pedido, \"sku\": sku}).fetchone()\n",
    "            if row:\n",
    "                return float(row[0])\n",
    "            else:\n",
    "                return None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro buscar_comissao_periodo p/ sku='{sku}': {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reprocessar_planilha(file_path):\n",
    "    \"\"\"\n",
    "    Reprocessa uma planilha já inserida no banco de dados.\n",
    "    - Garante que todos os pedidos existam na tabela sku_marketplace.\n",
    "    - Atualiza os valores de repasse normal sem somar repetidamente.\n",
    "    - Atualiza eventos sem duplicar.\n",
    "    \"\"\"\n",
    "    nome_arquivo = os.path.basename(file_path)\n",
    "    data_processo = parse_date_from_filename(nome_arquivo)\n",
    "\n",
    "    if not data_processo:\n",
    "        inserir_arquivos_processados(\n",
    "            nome_arquivo, None, 'ERRO', \"Erro ao extrair data do arquivo.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Atualiza o status para 'REPROCESSANDO'\n",
    "        with engine.begin() as conn:\n",
    "            # Em vez de 'REPROCESSANDO', use 'PENDENTE' ou outro status apropriado\n",
    "            upd = text(\"\"\"\n",
    "                UPDATE arquivos_processados\n",
    "                SET status = 'PENDENTE', observacoes = 'Reprocessamento solicitado.'\n",
    "                WHERE nome_arquivo = :na\n",
    "            \"\"\")\n",
    "            \n",
    "            conn.execute(upd, {\"na\": nome_arquivo})\n",
    "\n",
    "        df = pd.read_csv(file_path, sep=';')\n",
    "\n",
    "        # Tratar '-' como '0'\n",
    "        for col in [\"ValorPedido\", \"ValorFrete\", \"Comissao\", \"RepasseLiquido\"]:\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].replace('-', '0')\n",
    "\n",
    "        logger.info(f\"Reprocessando CSV '{nome_arquivo}'. Registros: {len(df)}\")\n",
    "\n",
    "        for idx, row in df.iterrows():\n",
    "            pedido_str = str(row.get(\"Pedido\", \"\")).strip()\n",
    "            data_pedido = None\n",
    "            if \"DataPedido\" in row:\n",
    "                dtp = pd.to_datetime(row[\"DataPedido\"], errors='coerce')\n",
    "                if pd.notnull(dtp):\n",
    "                    data_pedido = dtp.date()\n",
    "            data_repasse = None\n",
    "            if \"Ciclo\" in row:\n",
    "                drp = pd.to_datetime(row[\"Ciclo\"], errors='coerce')\n",
    "                if pd.notnull(drp):\n",
    "                    data_repasse = drp.date()\n",
    "\n",
    "            status_venda = str(row.get(\"StatusAtendimento\", \"\")).strip()\n",
    "            valor_pedido = float(row.get(\"ValorPedido\", 0.0))\n",
    "            valor_frete = float(row.get(\"ValorFrete\", 0.0))\n",
    "            valor_final = float(row.get(\"RepasseLiquido\", 0.0))\n",
    "\n",
    "            # 1) Garantir que o pedido exista na tabela sku_marketplace\n",
    "            sku_id = upsert_sku_marketplace(pedido=pedido_str, marketplace_id=5)\n",
    "\n",
    "            # 2) Se status for 'Repasse Normal' ou 'Repasse - Normal', atualiza os valores do repasse\n",
    "            if status_venda in [\"Repasse Normal\", \"Repasse - Normal\"]:\n",
    "                if sku_id:\n",
    "                    # Antes de atualizar, verificar se os valores já correspondem para evitar duplicação\n",
    "                    try:\n",
    "                        with engine.begin() as conn:\n",
    "                            sel = text(\"\"\"\n",
    "                                SELECT valor_liquido, valor_frete, valor_final\n",
    "                                FROM sku_marketplace\n",
    "                                WHERE id = :sid\n",
    "                            \"\"\")\n",
    "                            row_sku = conn.execute(sel, {\"sid\": sku_id}).fetchone()\n",
    "                            if row_sku:\n",
    "                                current_vliq, current_vfre, current_vfin = row_sku\n",
    "                                if (current_vliq != valor_pedido or\n",
    "                                    current_vfre != valor_frete or\n",
    "                                    current_vfin != valor_final):\n",
    "                                    atualizar_sku_marketplace_repasse(\n",
    "                                        pedido=pedido_str,\n",
    "                                        valor_pedido=valor_pedido,\n",
    "                                        valor_frete=valor_frete,\n",
    "                                        valor_final=valor_final,\n",
    "                                        marketplace_id=5\n",
    "                                    )\n",
    "                                else:\n",
    "                                    logger.info(f\"[sku_marketplace] Valores já atualizados para pedido={pedido_str}, ID={sku_id}\")\n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"Erro ao verificar valores para pedido={pedido_str}: {e}\")\n",
    "\n",
    "            # 3) upsert_evento_centauro (sempre)\n",
    "            upsert_evento_centauro(\n",
    "                numero_pedido=pedido_str,\n",
    "                tipo_evento=status_venda,\n",
    "                repasse_liquido=valor_final,\n",
    "                data=data_pedido,\n",
    "                data_repasse=data_repasse\n",
    "            )\n",
    "\n",
    "            # 4) Se status repasse normal, busca comissão\n",
    "            if status_venda in [\"Repasse Normal\", \"Repasse - Normal\"] and data_pedido and sku_id:\n",
    "                comissao_encontrada = buscar_comissao_periodo(\n",
    "                    data_pedido, pedido_str)\n",
    "                if comissao_encontrada is not None:\n",
    "                    # Verificar se a comissão já foi inserida para evitar duplicação\n",
    "                    try:\n",
    "                        with engine.begin() as conn:\n",
    "                            sel = text(\"\"\"\n",
    "                                SELECT COUNT(*)\n",
    "                                FROM comissoes_pedido\n",
    "                                WHERE data = :dt\n",
    "                                  AND porcentagem = :pc\n",
    "                                  AND sku_marketplace_id = :sid\n",
    "                            \"\"\")\n",
    "                            count = conn.execute(sel, {\n",
    "                                \"dt\": data_pedido,\n",
    "                                \"pc\": comissao_encontrada,\n",
    "                                \"sid\": sku_id\n",
    "                            }).scalar()\n",
    "                            if count == 0:\n",
    "                                inserir_comissoes_pedido(\n",
    "                                    data_pedido, comissao_encontrada, sku_id)\n",
    "                            else:\n",
    "                                logger.info(f\"[comissoes_pedido] Comissão já inserida para pedido={pedido_str}, ID={sku_id}\")\n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"Erro ao verificar comissão para pedido={pedido_str}: {e}\")\n",
    "                else:\n",
    "                    logger.info(\n",
    "                        f\"Sem comissão p/ '{pedido_str}' data={data_pedido}.\")\n",
    "\n",
    "        # Ao final, marcar o arquivo como reprocessado\n",
    "        with engine.begin() as conn:\n",
    "            upd = text(\"\"\"\n",
    "                UPDATE arquivos_processados\n",
    "                SET status = 'PROCESSADO', observacoes = 'Reprocessamento concluído.'\n",
    "                WHERE nome_arquivo = :na\n",
    "            \"\"\")\n",
    "            conn.execute(upd, {\"na\": nome_arquivo})\n",
    "        logger.info(f\"Reprocessamento do arquivo '{nome_arquivo}' concluído com sucesso.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao reprocessar '{nome_arquivo}': {e}\")\n",
    "        inserir_arquivos_processados(\n",
    "            nome_arquivo, data_processo, 'ERRO', str(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. EXECUÇÃO PRINCIPAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(reprocessar=True):\n",
    "    \"\"\"\n",
    "    Função principal para processar ou reprocessar arquivos CSV na pasta 'Repasse Centauro'.\n",
    "    \n",
    "    Parâmetros:\n",
    "    - reprocessar (bool): Se True, reprocessa todos os arquivos, mesmo os já processados.\n",
    "    \"\"\"\n",
    "    # Verificar se o marketplace_id=5 existe\n",
    "    if not verificar_marketplace_id(5):\n",
    "        logger.error(\"Marketplace ID 5 não encontrado. Encerrando o processamento.\")\n",
    "        return\n",
    "\n",
    "    # Ajuste o caminho abaixo para a pasta onde estão seus CSVs\n",
    "    base_dir = os.getcwd()\n",
    "    folder_path_centauro = os.path.join(base_dir, 'Repasse Centauro')\n",
    "\n",
    "    if not os.path.isdir(folder_path_centauro):\n",
    "        logger.error(f\"Pasta '{folder_path_centauro}' não encontrada.\")\n",
    "        inserir_arquivos_processados(\n",
    "            nome_arquivo=\"Centauro\",\n",
    "            data_processo=None,\n",
    "            status='ERRO',\n",
    "            observacoes=f\"Pasta '{folder_path_centauro}' não encontrada.\"\n",
    "        )\n",
    "        return\n",
    "\n",
    "    # Iterar sobre todos os arquivos na pasta\n",
    "    for filename in os.listdir(folder_path_centauro):\n",
    "        # Processar apenas arquivos .csv\n",
    "        if filename.lower().endswith('.csv'):\n",
    "            file_path = os.path.join(folder_path_centauro, filename)\n",
    "            if not os.path.exists(file_path):\n",
    "                logger.error(f\"Arquivo '{file_path}' não encontrado.\")\n",
    "                inserir_arquivos_processados(\n",
    "                    nome_arquivo=os.path.basename(file_path),\n",
    "                    data_processo=None,\n",
    "                    status='ERRO',\n",
    "                    observacoes=\"Arquivo não encontrado.\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            if reprocessar:\n",
    "                reprocessar_planilha(file_path)\n",
    "            else:\n",
    "                # Tentar inserir no 'arquivos_processados'. Se retornar False, pular o arquivo.\n",
    "                data_processo = parse_date_from_filename(filename)\n",
    "                processado = inserir_arquivos_processados(\n",
    "                    nome_arquivo=filename,\n",
    "                    data_processo=data_processo,\n",
    "                    status='PENDENTE',\n",
    "                    observacoes=\"Início do processamento.\"\n",
    "                )\n",
    "                if not processado:\n",
    "                    # Arquivo já foi processado, pular\n",
    "                    continue\n",
    "\n",
    "                # Processar o arquivo\n",
    "                processar_csv(file_path, reprocessar=reprocessar)\n",
    "        else:\n",
    "            logger.info(f\"Ignorando arquivo que não é CSV: {filename}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
